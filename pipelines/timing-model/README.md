# timing-model

This is an experiment in attempting to build a neural network model for
predicting timing sections in [osu!](https://osu.ppy.sh/) beatmaps. The high
level idea is to build an encoder-decoder RNN that can accurately produce
a sequence of timing sections for a song.

## Stages

Being a [popper](http://falsifiable.us/) pipeline, this experiment is divided
into stages.

### unzip-files

This stage only extracts the maps in the `maps` directory

### build-examples

This initial data processing stage parses the `.osu` beatmap files and
prepares the input data files. It saves the result in as a pickle in
`examples.p`.

In order to not use huge sequences of audio samples as input, instead I've
opted to reduce the dimensionality of the audio files using [librosa](https://librosa.github.io/).

Since the audio preprocessing is a highly cpu bound process, the work is split
among multiple processes. The number of processes is determined by the
`N_PROCS` environment variable.

### train

This builds a BRNN sequence to sequence model in keras and trains it with th
data generated by the previous strage.
